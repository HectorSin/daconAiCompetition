# ë¬´ì—­ í’ˆëª© ê³µí–‰ì„± ì˜ˆì¸¡ - ì¶”ì²œ ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸

## ğŸ“Š ëŒ€íšŒ íŠ¹ì„±
- **ë„ë©”ì¸**: ë¬´ì—­ ë°ì´í„° (100ê°œ ìˆ˜ì… í’ˆëª©)
- **Task**: ê³µí–‰ì„± íƒì§€ + ë¬´ì—­ëŸ‰ ì˜ˆì¸¡
- **ë°ì´í„°**: 2022.01 ~ 2025.07 (43ê°œì›”)
- **íŠ¹ì§•**: ê²½ì œ/ìˆ˜ìš” ì˜ˆì¸¡ ìœ ì‚¬

---

## ğŸ¯ ì¶”ì²œ ì‚¬ì „í•™ìŠµ ëª¨ë¸ (ìš°ì„ ìˆœìœ„)

### 1. **Chronos** (Amazon) â­â­â­â­â­
- **ì¥ì **: 
  - ì™„ì „ ì˜¤í”ˆì†ŒìŠ¤ & ë¬´ë£Œ
  - Zero-shot ì„±ëŠ¥ ìš°ìˆ˜
  - ì´ë¯¸ êµ¬í˜„ ì™„ë£Œ (`src/train_chronos.py`)
- **ì„¤ì¹˜**: 
  ```bash
  pip install git+https://github.com/amazon-science/chronos-forecasting.git
  ```
- **ëª¨ë¸ í¬ê¸°**:
  - `chronos-t5-small` (8M) - ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©
  - `chronos-t5-base` (46M) - ê· í˜•
  - `chronos-t5-large` (200M) - ìµœê³  ì„±ëŠ¥ âœ… ì¶”ì²œ
- **íŠ¹ì§•**: T5 ì•„í‚¤í…ì²˜, ì‹œê³„ì—´ì„ í† í°í™”í•˜ì—¬ í•™ìŠµ

---

### 2. **TimeGPT** (Nixtla) â­â­â­â­
- **ì¥ì **:
  - **ë¬´ì—­/ìˆ˜ìš” ì˜ˆì¸¡ íŠ¹í™”** (retail, finance ë°ì´í„° í•™ìŠµ)
  - 1000ì–µ+ ë°ì´í„° í¬ì¸íŠ¸ ì‚¬ì „í•™ìŠµ
  - API ë°©ì‹ìœ¼ë¡œ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥
  - Multivariate (ì™¸ë¶€ ë³€ìˆ˜ ì§€ì›)
- **ì£¼ì˜**: 
  - âš ï¸ **API ê¸°ë°˜ (ìœ ë£Œ)** - ë¬´ë£Œ í‹°ì–´ 500 requests/month
  - TimeGPT-2 ì¶œì‹œ (2024) - 60% ì •í™•ë„ í–¥ìƒ
- **ì„¤ì¹˜**:
  ```bash
  pip install nixtla
  ```
- **ì‚¬ìš© ì˜ˆì‹œ**:
  ```python
  from nixtla import NixtlaClient
  client = NixtlaClient(api_key='YOUR_API_KEY')
  forecast = client.forecast(df, h=1)
  ```
- **ë¬´ë£Œ í‹°ì–´**: https://nixtla.io
- **ì í•© ì—¬ë¶€**: 
  - âœ… ë¬´ì—­ ë°ì´í„°ì— ê°•í•¨ (ê²½ì œ ë„ë©”ì¸)
  - âŒ ì œì¶œ 20íšŒ ì œì•½ì—ì„œ API ë¹„ìš© ê³ ë ¤ í•„ìš”

---

### 3. **TimesFM** (Google) â­â­â­â­â­
- **ì¥ì **:
  - 200M íŒŒë¼ë¯¸í„°
  - 1000ì–µ+ ì‹œê³„ì—´ ë°ì´í„° ì‚¬ì „í•™ìŠµ
  - **ë¬´ë£Œ & ì˜¤í”ˆì†ŒìŠ¤**
  - íŒ¨ì¹˜ ê¸°ë°˜ ì²˜ë¦¬ (íš¨ìœ¨ì )
- **ì„¤ì¹˜**:
  ```bash
  pip install timesfm
  # ë˜ëŠ”
  git clone https://github.com/google-research/timesfm
  ```
- **íŠ¹ì§•**: Decoder-only Transformer
- **ì í•© ì—¬ë¶€**: âœ… Chronos ëŒ€ì•ˆ/ì•™ìƒë¸”ìš©

---

### 4. **Lag-Llama** (ServiceNow) â­â­â­â­
- **ì¥ì **:
  - **Fine-tuning ì‰¬ì›€** (ë¬´ì—­ ë°ì´í„°ì— ì ì‘)
  - í™•ë¥ ì  ì˜ˆì¸¡ (ë¶ˆí™•ì‹¤ì„± ì œê³µ)
  - ì™„ì „ ì˜¤í”ˆì†ŒìŠ¤
- **ì„¤ì¹˜**:
  ```bash
  pip install gluonts
  # Hugging Faceì—ì„œ ëª¨ë¸ ë¡œë“œ
  ```
- **ì‚¬ìš© ì˜ˆì‹œ**:
  ```python
  from gluonts.model.lag_llama import LagLlamaEstimator
  ```
- **ì í•© ì—¬ë¶€**: 
  - âœ… Fine-tuningìœ¼ë¡œ ë„ë©”ì¸ ì ì‘ ê°€ëŠ¥
  - ğŸ“Š í™•ë¥ ì  ì˜ˆì¸¡ìœ¼ë¡œ ë¦¬ìŠ¤í¬ ê´€ë¦¬

---

### 5. **Moirai** (Salesforce) â­â­â­
- **ì¥ì **: ë‹¤ì–‘í•œ ì£¼ê¸° ì²˜ë¦¬
- **ì˜¤í”ˆì†ŒìŠ¤**: âœ…
- **ì í•© ì—¬ë¶€**: ì•™ìƒë¸” ì¶”ê°€ìš©

---

### 6. **AutoGluon-TimeSeries** â­â­â­â­
- **ì¥ì **:
  - **AutoML** - ìë™ ëª¨ë¸ ì„ íƒ ë° ì•™ìƒë¸”
  - Chronos, TimeGPT ë“± í†µí•©
  - AWS ì§€ì›
- **ì„¤ì¹˜**:
  ```bash
  pip install autogluon.timeseries
  ```
- **ì‚¬ìš© ì˜ˆì‹œ**:
  ```python
  from autogluon.timeseries import TimeSeriesPredictor
  predictor = TimeSeriesPredictor().fit(train_data)
  predictions = predictor.predict(test_data)
  ```
- **ì í•© ì—¬ë¶€**: 
  - âœ… ë¹ ë¥¸ ë² ì´ìŠ¤ë¼ì¸ êµ¬ì¶•
  - ğŸ“ˆ ìë™ ì•™ìƒë¸”

---

## ğŸ¯ ë¬´ì—­ ë°ì´í„° íŠ¹í™” ì ‘ê·¼ë²•

### ê²½ì œ/ê¸ˆìœµ ì‹œê³„ì—´ ëª¨ë¸
1. **LSTM/GRU ê¸°ë°˜ ëª¨ë¸**
   - ê²½ì œ ë°ì´í„°ì˜ ì¥ê¸° ì˜ì¡´ì„± í¬ì°©
   - ìì²´ í•™ìŠµ í•„ìš”

2. **XGBoost/LightGBM** (ì „í†µì  ë°©ë²•)
   - íŠ¹ì§• ê³µí•™ê³¼ ê²°í•© ì‹œ ê°•ë ¥
   - ì´ë¯¸ êµ¬í˜„ ì™„ë£Œ (`src/train_global_model.py`)

3. **Hybrid ì ‘ê·¼**
   - Foundation Model + ë„ë©”ì¸ íŠ¹ì§•
   - **ì¶”ì²œ**: Chronos + ê³µí–‰ì„± íŠ¹ì§• + LightGBM

---

## ğŸš€ ìµœì¢… ì¶”ì²œ ì „ëµ

### Scenario A: ë¹ ë¥¸ êµ¬í˜„ (2ì¼)
```
Chronos (ë‹¨ë…) 
â†’ ì œì¶œ #1
â†’ ì ìˆ˜ í™•ì¸
```

### Scenario B: ì•™ìƒë¸” (3-4ì¼) â­ ì¶”ì²œ
```
Base Models:
â”œâ”€â”€ Chronos (ì¼ë°˜í™”)
â”œâ”€â”€ N-HiTS (ê³„ì¸µì  íŒ¨í„´)
â””â”€â”€ LightGBM (ê³µí–‰ì„± íŠ¹ì§•)
    â†“
Stacking Meta-Learner
    â†“
ìµœì¢… ì˜ˆì¸¡
```

### Scenario C: ìµœê°• ì¡°í•© (5ì¼)
```
Base Models:
â”œâ”€â”€ Chronos
â”œâ”€â”€ TimesFM
â”œâ”€â”€ Lag-Llama (Fine-tuned)
â””â”€â”€ LightGBM
    â†“
Stacking Ensemble
    â†“
ê³µí–‰ì„± ìµœì í™”
    â†“
ìµœì¢… ì˜ˆì¸¡
```

---

## ğŸ“¦ ì„¤ì¹˜ ëª…ë ¹ì–´ ëª¨ìŒ

```bash
# í•„ìˆ˜ (ì´ë¯¸ ì‹¤í–‰)
pip install git+https://github.com/amazon-science/chronos-forecasting.git

# TimesFM (ì„ íƒ)
pip install timesfm

# Lag-Llama (ì„ íƒ)
pip install gluonts

# TimeGPT (API, ì„ íƒ)
pip install nixtla

# AutoGluon (ì„ íƒ)
pip install autogluon.timeseries
```

---

## ğŸ¬ ë‹¤ìŒ ë‹¨ê³„

### ë‹¨ê¸° (ì˜¤ëŠ˜~ë‚´ì¼)
1. âœ… Chronos ì‹¤í–‰
   ```bash
   python src/train_chronos.py
   ```
2. âœ… ì œì¶œ #1
3. âœ… ì•™ìƒë¸” í…ŒìŠ¤íŠ¸
   ```bash
   python src/ensemble_chronos_nhits.py
   ```

### ì¤‘ê¸° (2-3ì¼ì°¨)
4. Stacking Ensemble
   ```bash
   python src/ensemble_stacking.py
   ```
5. TimesFM ì¶”ê°€ (ì‹œê°„ ìˆìœ¼ë©´)
6. Fine-tuning ì‹¤í—˜

### ì¥ê¸° (4-5ì¼ì°¨)
7. ìµœì  ì¡°í•© ì°¾ê¸°
8. ê³µí–‰ì„± ì„ê³„ê°’ ìµœì í™”
9. ìµœì¢… ì œì¶œ

---

## ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸

### ë¬´ì—­ ë°ì´í„° íŠ¹ì„±
- **ê²½ì œ ë„ë©”ì¸** â†’ TimeGPT, Chronos ìœ ë¦¬
- **ê³µí–‰ì„± ì¤‘ìš”** â†’ ì „í†µì  íŠ¹ì§• ê³µí•™ í•„ìˆ˜
- **ì›”ë³„ ë°ì´í„°** â†’ ê³„ì ˆì„± ê°•í•¨ â†’ N-HiTS ìœ ìš©

### ì•™ìƒë¸” ì´ìœ 
- Foundation Model: ì¼ë°˜ì  íŒ¨í„´ í•™ìŠµ
- ë„ë©”ì¸ ëª¨ë¸: ë¬´ì—­ íŠ¹í™” íŠ¹ì§• í™œìš©
- Meta-Learner: ìë™ ê°€ì¤‘ì¹˜ ìµœì í™”

---

## ğŸ“š ì°¸ê³  ìë£Œ

- Chronos: https://github.com/amazon-science/chronos-forecasting
- TimeGPT: https://docs.nixtla.io
- TimesFM: https://github.com/google-research/timesfm
- Lag-Llama: https://huggingface.co/time-series-foundation-models/Lag-Llama
- AutoGluon: https://auto.gluon.ai/stable/tutorials/timeseries/

---

**ì¶”ì²œ ì‹œì‘ì **: Chronos â†’ Stacking Ensemble â†’ ì œì¶œ!
